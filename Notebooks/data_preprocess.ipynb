{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理笔记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\biomedCLIP\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "from sympy import Q \n",
    "import torch\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from typing import Any, Dict, Optional, Tuple, Union\n",
    "import open_clip\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torchvision.transforms import InterpolationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "# from sympy import Q \n",
    "import torch\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from typing import Any, Dict, Optional, Tuple, Union\n",
    "import open_clip\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "try:\n",
    "    BICUBIC = InterpolationMode.BICUBIC\n",
    "except ImportError:\n",
    "    BICUBIC = Image.BICUBIC\n",
    "\n",
    "def _convert_image_to_rgb(image):\n",
    "    return image.convert(\"RGB\")\n",
    "\n",
    "def _transform(n_px):\n",
    "    return Compose([\n",
    "        Resize(n_px, interpolation=BICUBIC),\n",
    "        CenterCrop(n_px),\n",
    "        _convert_image_to_rgb,\n",
    "        ToTensor(),\n",
    "        Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "def CLIP_Process(image_path, dest):\n",
    "    img = Image.open(image_path)\n",
    "    a = 224\n",
    "    b = _transform(a)\n",
    "    c = b(img)\n",
    "    if ((dest.split(\".\")[-1]) != \"pth\"):\n",
    "      dest+=\".pth\"\n",
    "      \n",
    "    torch.save(c, dest)\n",
    "    return c\n",
    "\n",
    "\n",
    "\n",
    "OPENAI_DATASET_MEAN = (0.48145466, 0.4578275, 0.40821073)\n",
    "OPENAI_DATASET_STD = (0.26862954, 0.26130258, 0.27577711)\n",
    "\n",
    "_FIELDS = '__dataclass_fields__'\n",
    "def _is_dataclass_instance(obj):\n",
    "    \"\"\"Returns True if obj is an instance of a dataclass.\"\"\"\n",
    "    return hasattr(type(obj), _FIELDS)\n",
    "\n",
    "def asdict(obj, *, dict_factory=dict):\n",
    "    \"\"\"Return the fields of a dataclass instance as a new dictionary mapping\n",
    "    field names to field values.\n",
    "\n",
    "    Example usage:\n",
    "\n",
    "      @dataclass\n",
    "      class C:\n",
    "          x: int\n",
    "          y: int\n",
    "\n",
    "      c = C(1, 2)\n",
    "      assert asdict(c) == {'x': 1, 'y': 2}\n",
    "\n",
    "    If given, 'dict_factory' will be used instead of built-in dict.\n",
    "    The function applies recursively to field values that are\n",
    "    dataclass instances. This will also look into built-in containers:\n",
    "    tuples, lists, and dicts.\n",
    "    \"\"\"\n",
    "    if not _is_dataclass_instance(obj):\n",
    "        raise TypeError(\"asdict() should be called on dataclass instances\")\n",
    "    return _asdict_inner(obj, dict_factory)\n",
    "\n",
    "\n",
    "def _asdict_inner(obj, dict_factory):\n",
    "    if _is_dataclass_instance(obj):\n",
    "        result = []\n",
    "        for f in fields(obj):\n",
    "            value = _asdict_inner(getattr(obj, f.name), dict_factory)\n",
    "            result.append((f.name, value))\n",
    "        return dict_factory(result)\n",
    "    elif isinstance(obj, tuple) and hasattr(obj, '_fields'):\n",
    "        # obj is a namedtuple.  Recurse into it, but the returned\n",
    "        # object is another namedtuple of the same type.  This is\n",
    "        # similar to how other list- or tuple-derived classes are\n",
    "        # treated (see below), but we just need to create them\n",
    "        # differently because a namedtuple's __init__ needs to be\n",
    "        # called differently (see bpo-34363).\n",
    "\n",
    "        # I'm not using namedtuple's _asdict()\n",
    "        # method, because:\n",
    "        # - it does not recurse in to the namedtuple fields and\n",
    "        #   convert them to dicts (using dict_factory).\n",
    "        # - I don't actually want to return a dict here.  The main\n",
    "        #   use case here is json.dumps, and it handles converting\n",
    "        #   namedtuples to lists.  Admittedly we're losing some\n",
    "        #   information here when we produce a json list instead of a\n",
    "        #   dict.  Note that if we returned dicts here instead of\n",
    "        #   namedtuples, we could no longer call asdict() on a data\n",
    "        #   structure where a namedtuple was used as a dict key.\n",
    "\n",
    "        return type(obj)(*[_asdict_inner(v, dict_factory) for v in obj])\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        # Assume we can create an object of this type by passing in a\n",
    "        # generator (which is not true for namedtuples, handled\n",
    "        # above).\n",
    "        return type(obj)(_asdict_inner(v, dict_factory) for v in obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return type(obj)((_asdict_inner(k, dict_factory),\n",
    "                          _asdict_inner(v, dict_factory))\n",
    "                         for k, v in obj.items())\n",
    "    else:\n",
    "        return copy.deepcopy(obj)\n",
    "\n",
    "class AugmentationCfg:\n",
    "    scale: Tuple[float, float] = (0.9, 1.0)\n",
    "    ratio: Optional[Tuple[float, float]] = None\n",
    "    color_jitter: Optional[Union[float, Tuple[float, float, float]]] = None\n",
    "    interpolation: Optional[str] = None\n",
    "    re_prob: Optional[float] = None\n",
    "    re_count: Optional[int] = None\n",
    "    use_timm: bool = False\n",
    "\n",
    "class ResizeMaxSize(nn.Module):\n",
    "\n",
    "    def __init__(self, max_size, interpolation=InterpolationMode.BICUBIC, fn='max', fill=0):\n",
    "        super().__init__()\n",
    "        if not isinstance(max_size, int):\n",
    "            raise TypeError(f\"Size should be int. Got {type(max_size)}\")\n",
    "        self.max_size = max_size\n",
    "        self.interpolation = interpolation\n",
    "        self.fn = min if fn == 'min' else min\n",
    "        self.fill = fill\n",
    "\n",
    "    def forward(self, img):\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            height, width = img.shape[:2]\n",
    "        else:\n",
    "            width, height = img.size\n",
    "        scale = self.max_size / float(max(height, width))\n",
    "        new_size = tuple(round(dim * scale) for dim in (height, width))\n",
    "        if scale != 1.0:\n",
    "            img = F.resize(img, new_size, self.interpolation)\n",
    "        if not width == height:\n",
    "            pad_h = self.max_size - new_size[0]\n",
    "            pad_w = self.max_size - new_size[1]\n",
    "            img = F.pad(img, padding=[pad_w//2, pad_h//2, pad_w - pad_w//2, pad_h - pad_h//2], fill=self.fill)\n",
    "        return img\n",
    "\n",
    "\n",
    "def image_transform(\n",
    "        image_size: int,\n",
    "        is_train:bool = False,\n",
    "        mean: Optional[Tuple[float, ...]] = None,\n",
    "        std: Optional[Tuple[float, ...]] = None,\n",
    "        resize_longest_max: bool = False,\n",
    "        fill_color: int = 0,\n",
    "        aug_cfg: Optional[Union[Dict[str, Any], AugmentationCfg]] = None,\n",
    "):\n",
    "    mean = mean or OPENAI_DATASET_MEAN\n",
    "    if not isinstance(mean, (list, tuple)):\n",
    "        mean = (mean,) * 3\n",
    "\n",
    "    std = std or OPENAI_DATASET_STD\n",
    "    if not isinstance(std, (list, tuple)):\n",
    "        std = (std,) * 3\n",
    "\n",
    "    if isinstance(image_size, (list, tuple)) and image_size[0] == image_size[1]:\n",
    "        # for square size, pass size as int so that Resize() uses aspect preserving shortest edge\n",
    "        image_size = image_size[0]\n",
    "\n",
    "    if isinstance(aug_cfg, dict):\n",
    "        aug_cfg = AugmentationCfg(**aug_cfg)\n",
    "    else:\n",
    "        aug_cfg = aug_cfg or AugmentationCfg()\n",
    "    normalize = Normalize(mean=mean, std=std)\n",
    "    if is_train:\n",
    "        raise NotImplemented(\"!!LDS!!\")\n",
    "        # aug_cfg_dict = {k: v for k, v in asdict(aug_cfg).items() if v is not None}\n",
    "        # use_timm = aug_cfg_dict.pop('use_timm', False)\n",
    "        # if use_timm:\n",
    "        #     from timm.data import create_transform  # timm can still be optional\n",
    "        #     if isinstance(image_size, (tuple, list)):\n",
    "        #         assert len(image_size) >= 2\n",
    "        #         input_size = (3,) + image_size[-2:]\n",
    "        #     else:\n",
    "        #         input_size = (3, image_size, image_size)\n",
    "        #     # by default, timm aug randomly alternates bicubic & bilinear for better robustness at inference time\n",
    "        #     aug_cfg_dict.setdefault('interpolation', 'random')\n",
    "        #     aug_cfg_dict.setdefault('color_jitter', None)  # disable by default\n",
    "        #     train_transform = create_transform(\n",
    "        #         input_size=input_size,\n",
    "        #         is_training=True,\n",
    "        #         hflip=0.,\n",
    "        #         mean=mean,\n",
    "        #         std=std,\n",
    "        #         re_mode='pixel',\n",
    "        #         **aug_cfg_dict,\n",
    "        #     )\n",
    "        # else:\n",
    "        #     train_transform = Compose([\n",
    "        #         RandomResizedCrop(\n",
    "        #             image_size,\n",
    "        #             scale=aug_cfg_dict.pop('scale'),\n",
    "        #             interpolation=InterpolationMode.BICUBIC,\n",
    "        #         ),\n",
    "        #         _convert_to_rgb,\n",
    "        #         ToTensor(),\n",
    "        #         normalize,\n",
    "        #     ])\n",
    "        #     if aug_cfg_dict:\n",
    "        #         warnings.warn(f'Unused augmentation cfg items, specify `use_timm` to use ({list(aug_cfg_dict.keys())}).')\n",
    "        # return train_transform\n",
    "    else:\n",
    "        if resize_longest_max:\n",
    "            transforms = [\n",
    "                ResizeMaxSize(image_size, fill=fill_color)\n",
    "            ]\n",
    "        else:\n",
    "            transforms = [\n",
    "                Resize(image_size, interpolation=InterpolationMode.BICUBIC),\n",
    "                CenterCrop(image_size),\n",
    "            ]\n",
    "        transforms.extend([\n",
    "            _convert_image_to_rgb,\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "        return Compose(transforms)\n",
    "\n",
    "\n",
    "def BiomedCLIP_processor(image_path, dest):\n",
    "    img = Image.open(image_path)\n",
    "    preprocess_val = image_transform(224)\n",
    "    data = preprocess_val(img)\n",
    "    if ((dest.split(\".\")[-1]) != \"pth\"):\n",
    "      dest+=\".pth\"\n",
    "      \n",
    "    torch.save(data, dest)\n",
    "    return data\n",
    "   \n",
    "  \n",
    "\n",
    "if  __name__ == \"__main__\":\n",
    "  image_path = r\"D:\\project_x_ray_CLIP\\data\\physionet.org\\files\\mimic-cxr-jpg\\2.0.0\\files\\p10\\p10000898\\s54205396\\9e7a6aae-2580e589-6212d336-9813ebbd-a9239a34.jpg\"\n",
    "  img = Image.open(image_path)\n",
    "  process = BiomedCLIP_processor(image_path, r'D:\\exchange\\ShanghaiTech\\learning\\code\\diagnosisP\\x_ray_constrastive\\output/biomed_tensor_var.pth')\n",
    "  # print(process)\n",
    "  process2 = CLIP_Process(image_path, r'D:\\exchange\\ShanghaiTech\\learning\\code\\diagnosisP\\x_ray_constrastive\\output/_tensor_var.pth')\n",
    "  \n",
    "\n",
    "  # a = 224\n",
    "  # b = _transform(a)\n",
    "  # print((process == process2).sum())\n",
    "  # print(3*224*224)\n",
    "\n",
    "\n",
    "  # clip_model, preprocess_train, clip_processor = open_clip.create_model_and_transforms('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
    "  # clip_model2, clip_processor2  = clip.load(\"ViT-B/32\",)\n",
    "\n",
    "  # a = clip_processor(Image.open(image_path))\n",
    "  # b = clip_processor2(Image.open(image_path))\n",
    "  # print((a == b).sum())\n",
    "  # print((a == process2).sum())\n",
    "  # c = b(img)\n",
    "\n",
    "  # torch.save(c, r'D:\\exchange\\ShanghaiTech\\learning\\code\\diagnosisP\\x_ray_constrastive\\output/tensor_var.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home_data/home/v-liudsh/miniconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "  File \"/tmp/ipykernel_214912/1659672463.py\", line 1, in <module>\n",
      "  File \"/home_data/home/v-liudsh/miniconda3/envs/torch/lib/python3.8/site-packages/pandas/__init__.py\", line 141, in <module>\n",
      "  File \"/home_data/home/v-liudsh/miniconda3/envs/torch/lib/python3.8/site-packages/pandas/io/api.py\", line 26, in <module>\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 839, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 934, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1033, in get_data\n",
      "MemoryError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home_data/home/v-liudsh/miniconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home_data/home/v-liudsh/miniconda3/envs/torch/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1396, in structured_traceback\n",
      "  File \"/home_data/home/v-liudsh/miniconda3/envs/torch/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1287, in structured_traceback\n",
      "  File \"/home_data/home/v-liudsh/miniconda3/envs/torch/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1140, in structured_traceback\n",
      "  File \"/home_data/home/v-liudsh/miniconda3/envs/torch/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1030, in format_exception_as_a_whole\n",
      "  File \"/home_data/home/v-liudsh/miniconda3/envs/torch/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1105, in get_records\n",
      "  File \"/home_data/home/v-liudsh/miniconda3/envs/torch/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 183, in get_line_number_of_frame\n",
      "  File \"/home_data/home/v-liudsh/miniconda3/envs/torch/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 148, in count_lines_in_py_file\n",
      "MemoryError\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "pwd = os.getcwd()\n",
    "data = pd.read_csv(pwd + r\"/../data/mimic-cxr-train/P10_12_train_12_16_labels14.csv\")\n",
    "print(data.file_path[10])\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m file_path \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mfile_path\n\u001b[1;32m      5\u001b[0m filename \u001b[39m=\u001b[39m file_path[\u001b[39m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(filename)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "file_path = data.file_path\n",
    "filename = file_path[0]\n",
    "print(filename)\n",
    "\n",
    "def change_suffix(filename, custom = \"\"):\n",
    "    # path_obj = Path(filename)\n",
    "    # filename = path_obj.stem\n",
    "    # # print(filename)\n",
    "    # # 构建新的文件路径\n",
    "    # new_file_path = path_obj.with_suffix(new_suffix)\n",
    "    # print(new_file_path)\n",
    "    modified_string = filename.replace(\"//\", \"/\")\n",
    "    modified_string = modified_string.replace(\"D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/\", '/public_bme/data/lds/')\n",
    "    filename, file_extension = os.path.splitext(modified_string)\n",
    "    # print(filename)\n",
    "    return filename+f\"_{custom}\"+\".pth\"\n",
    "data['Biomed_img_tensor_path'] = data['file_path'].apply(lambda x: change_suffix(x, 'biomed'))\n",
    "data['Clip_img_tensor_path'] = data['file_path'].apply(lambda x: change_suffix(x, \"clip\"))\n",
    "data['Biovil_img_tensor_path'] = data['file_path'].apply(lambda x: change_suffix(x, \"biovil\"))\n",
    "data.to_csv(pwd + r\"/../data/mimic-cxr-train/P10_12_train_1_29_labels14_biovil.csv\", index=False)\n",
    "data = pd.read_csv(pwd + r\"/../data/mimic-cxr-train/P10_12_train_1_29_labels14_biovil.csv\", index_col=0)\n",
    "print(len(data))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10/p10000032/s50414267/02aa804e-bde0afdd-112c0b34-7bc16630-4e384014_biomed.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10/p10000032/s50414267/02aa804e-bde0afdd-112c0b34-7bc16630-4e384014_clip.pth'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.head()\n",
    "print(data.iloc[0].BiomedClip_tensor_path)\n",
    "data.iloc[0].tensor_path    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109859\n",
      "109859 109859\n",
      "0.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10//p10000032/s50414267//02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10/p10000032/s50414267/02aa804e-bde0afdd-112c0b34-7bc16630-4e384014_biomed.pth\n",
      "1.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10//p10296754/s52777980//9af1366b-2f3aa91b-4a214fab-6781ec3c-c1aa55f1.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10/p10296754/s52777980/9af1366b-2f3aa91b-4a214fab-6781ec3c-c1aa55f1_biomed.pth\n",
      "2.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10//p10603866/s51734064//659621c8-876bf82c-56720a67-75cb495b-c92fa705.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10/p10603866/s51734064/659621c8-876bf82c-56720a67-75cb495b-c92fa705_biomed.pth\n",
      "3.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10//p10913892/s51308209//80013549-a1628764-4c734ce3-5add036e-0e535e5b.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10/p10913892/s51308209/80013549-a1628764-4c734ce3-5add036e-0e535e5b_biomed.pth\n",
      "4.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p11//p11216730/s59588159//ee9b7fa1-4b09c293-94e9ad9f-78c70bfe-d4e7754c.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p11/p11216730/s59588159/ee9b7fa1-4b09c293-94e9ad9f-78c70bfe-d4e7754c_biomed.pth\n",
      "5.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p11//p11522379/s53696097//fd39986f-4a7f992d-ec3f2734-ff112f6d-fb0a9f79.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p11/p11522379/s53696097/fd39986f-4a7f992d-ec3f2734-ff112f6d-fb0a9f79_biomed.pth\n",
      "6.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p11//p11805066/s54518343//451d3f67-988855bd-528302f2-b9645af6-2ef03e83.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p11/p11805066/s54518343/451d3f67-988855bd-528302f2-b9645af6-2ef03e83_biomed.pth\n",
      "7.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p12//p12085305/s51744560//0fce1868-ca908605-fc636297-a07600fc-194caf8d.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p12/p12085305/s51744560/0fce1868-ca908605-fc636297-a07600fc-194caf8d_biomed.pth\n",
      "8.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p12//p12384056/s54268668//2192aa8f-ef1a5c85-90f8e783-7a07c0c3-a6f61f5f.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p12/p12384056/s54268668/2192aa8f-ef1a5c85-90f8e783-7a07c0c3-a6f61f5f_biomed.pth\n",
      "9.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p12//p12684132/s58368894//adc4b984-34d6e63d-df1f02ed-534adc30-a1d8c062.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p12/p12684132/s58368894/adc4b984-34d6e63d-df1f02ed-534adc30-a1d8c062_biomed.pth\n",
      "10.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p12//p12989304/s59289482//da799a43-06e9d5e0-61f829eb-ef8ec643-bfd1847d.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p12/p12989304/s59289482/da799a43-06e9d5e0-61f829eb-ef8ec643-bfd1847d_biomed.pth\n",
      "109859\n",
      "109859 109859\n",
      "0.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10//p10000032/s50414267//02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10/p10000032/s50414267/02aa804e-bde0afdd-112c0b34-7bc16630-4e384014_clip.pth\n",
      "1.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10//p10296754/s52777980//9af1366b-2f3aa91b-4a214fab-6781ec3c-c1aa55f1.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10/p10296754/s52777980/9af1366b-2f3aa91b-4a214fab-6781ec3c-c1aa55f1_clip.pth\n",
      "2.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10//p10603866/s51734064//659621c8-876bf82c-56720a67-75cb495b-c92fa705.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10/p10603866/s51734064/659621c8-876bf82c-56720a67-75cb495b-c92fa705_clip.pth\n",
      "3.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10//p10913892/s51308209//80013549-a1628764-4c734ce3-5add036e-0e535e5b.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10/p10913892/s51308209/80013549-a1628764-4c734ce3-5add036e-0e535e5b_clip.pth\n",
      "4.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p11//p11216730/s59588159//ee9b7fa1-4b09c293-94e9ad9f-78c70bfe-d4e7754c.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p11/p11216730/s59588159/ee9b7fa1-4b09c293-94e9ad9f-78c70bfe-d4e7754c_clip.pth\n",
      "5.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p11//p11522379/s53696097//fd39986f-4a7f992d-ec3f2734-ff112f6d-fb0a9f79.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p11/p11522379/s53696097/fd39986f-4a7f992d-ec3f2734-ff112f6d-fb0a9f79_clip.pth\n",
      "6.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p11//p11805066/s54518343//451d3f67-988855bd-528302f2-b9645af6-2ef03e83.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p11/p11805066/s54518343/451d3f67-988855bd-528302f2-b9645af6-2ef03e83_clip.pth\n",
      "7.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p12//p12085305/s51744560//0fce1868-ca908605-fc636297-a07600fc-194caf8d.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p12/p12085305/s51744560/0fce1868-ca908605-fc636297-a07600fc-194caf8d_clip.pth\n",
      "8.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p12//p12384056/s54268668//2192aa8f-ef1a5c85-90f8e783-7a07c0c3-a6f61f5f.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p12/p12384056/s54268668/2192aa8f-ef1a5c85-90f8e783-7a07c0c3-a6f61f5f_clip.pth\n",
      "9.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p12//p12684132/s58368894//adc4b984-34d6e63d-df1f02ed-534adc30-a1d8c062.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p12/p12684132/s58368894/adc4b984-34d6e63d-df1f02ed-534adc30-a1d8c062_clip.pth\n",
      "10.0\n",
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p12//p12989304/s59289482//da799a43-06e9d5e0-61f829eb-ef8ec643-bfd1847d.jpg D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p12/p12989304/s59289482/da799a43-06e9d5e0-61f829eb-ef8ec643-bfd1847d_clip.pth\n"
     ]
    }
   ],
   "source": [
    "img_paths = data.file_path\n",
    "tensor_path = data.BiomedClip_tensor_path\n",
    "total = len(tensor_path)\n",
    "print(total)\n",
    "print(len(tensor_path), len(img_paths))\n",
    "dev = total // 10\n",
    "count = 0\n",
    "# for i, j in enumerate(img_paths):\n",
    "#   print(type(j), j,  tensor_path[i])\n",
    "#   CLIP_Process(str(j), tensor_path[i])\n",
    "#   if i % dev == 0:\n",
    "#     print(i)\n",
    "#   else:\n",
    "#     continue\n",
    "\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "for  (img_path, tensor_path) in (zip(img_paths, tensor_path)):\n",
    "  try:\n",
    "    # print( type(img_path), img_path, type(ten,,l[pl-0o-or_path), tensor_path)\n",
    "    BiomedCLIP_processor(img_path, tensor_path)\n",
    "    if count%dev == 0:\n",
    "      print(count/dev)\n",
    "      print(img_path, tensor_path)\n",
    "    count+=1\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_paths = data.file_path\n",
    "tensor_path = data.tensor_path\n",
    "total = len(tensor_path)\n",
    "print(total)\n",
    "print(len(tensor_path), len(img_paths))\n",
    "dev = total // 10\n",
    "count = 0\n",
    "\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "for  (img_path, tensor_path) in (zip(img_paths, tensor_path)):\n",
    "  try:\n",
    "    # print( type(img_path), img_path, type(ten,,l[pl-0o-or_path), tensor_path)\n",
    "    CLIP_Process(img_path, tensor_path)\n",
    "    if count%dev == 0:\n",
    "      print(count/dev)\n",
    "      print(img_path, tensor_path)\n",
    "    count+=1\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing data image process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10/p10032725/s50331901/687754ce-7420bfd3-0a19911f-a27a3916-9019cd53.jpg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "pwd = os.getcwd()\n",
    "data = pd.read_csv(pwd + r\"/data/mimic-cxr-train/P10_12_test_12_1.csv\")\n",
    "source = \"/public_bme/data/lds\"\n",
    "data.file_path[0].replace(\"//\", '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1175\n",
      "1175 1175\n",
      "0.0\n",
      "/public_bme/data/lds/p10/p10032725/s50331901/687754ce-7420bfd3-0a19911f-a27a3916-9019cd53.jpg /public_bme/data/lds/p10/p10032725/s50331901/687754ce-7420bfd3-0a19911f-a27a3916-9019cd53_biomed.pth\n",
      "1.0\n",
      "/public_bme/data/lds/p10/p10439781/s51129150/1d74ca1d-12ac2785-bd84a322-376f04bc-b9fdaa99.jpg /public_bme/data/lds/p10/p10439781/s51129150/1d74ca1d-12ac2785-bd84a322-376f04bc-b9fdaa99_biomed.pth\n",
      "2.0\n",
      "/public_bme/data/lds/p10/p10885696/s56443683/5b429228-9769c874-369577de-11d25077-c9ad1f2b.jpg /public_bme/data/lds/p10/p10885696/s56443683/5b429228-9769c874-369577de-11d25077-c9ad1f2b_biomed.pth\n",
      "3.0\n",
      "/public_bme/data/lds/p10/p10975446/s55185117/0d768fcf-0bb1bca1-eb1fe1d6-686b876b-675a2e95.jpg /public_bme/data/lds/p10/p10975446/s55185117/0d768fcf-0bb1bca1-eb1fe1d6-686b876b-675a2e95_biomed.pth\n",
      "4.0\n",
      "/public_bme/data/lds/p11/p11293517/s51788928/d488ce83-528fa722-abe67b2b-ef58f254-0d7db9b2.jpg /public_bme/data/lds/p11/p11293517/s51788928/d488ce83-528fa722-abe67b2b-ef58f254-0d7db9b2_biomed.pth\n",
      "5.0\n",
      "/public_bme/data/lds/p11/p11474065/s59083645/7bcd081b-869f44f4-57a93477-646a8796-ee97546c.jpg /public_bme/data/lds/p11/p11474065/s59083645/7bcd081b-869f44f4-57a93477-646a8796-ee97546c_biomed.pth\n",
      "6.0\n",
      "/public_bme/data/lds/p11/p11880923/s56440140/421dff97-6d2b4aab-02ed28a8-54dd67f9-da2f957b.jpg /public_bme/data/lds/p11/p11880923/s56440140/421dff97-6d2b4aab-02ed28a8-54dd67f9-da2f957b_biomed.pth\n",
      "7.0\n",
      "/public_bme/data/lds/p12/p12185775/s50729749/42ca390f-5819f578-c74fd59e-a7561a1a-0040b454.jpg /public_bme/data/lds/p12/p12185775/s50729749/42ca390f-5819f578-c74fd59e-a7561a1a-0040b454_biomed.pth\n",
      "8.0\n",
      "/public_bme/data/lds/p12/p12475198/s53378145/ba5b5b5f-13d50976-7e931ab9-b5cae769-76a2d17e.jpg /public_bme/data/lds/p12/p12475198/s53378145/ba5b5b5f-13d50976-7e931ab9-b5cae769-76a2d17e_biomed.pth\n",
      "9.0\n",
      "/public_bme/data/lds/p12/p12702423/s51244261/17ff7369-20912497-3b539b61-9c4ace20-7dc7fa12.jpg /public_bme/data/lds/p12/p12702423/s51244261/17ff7369-20912497-3b539b61-9c4ace20-7dc7fa12_biomed.pth\n",
      "10.0\n",
      "/public_bme/data/lds/p12/p12963531/s59505688/44f44165-06ab81a8-b9d0f4c2-2c65e354-bd5cbfbf.jpg /public_bme/data/lds/p12/p12963531/s59505688/44f44165-06ab81a8-b9d0f4c2-2c65e354-bd5cbfbf_biomed.pth\n",
      "1175\n",
      "1175 1175\n",
      "0.0\n",
      "/public_bme/data/lds/p10/p10032725/s50331901/687754ce-7420bfd3-0a19911f-a27a3916-9019cd53.jpg /public_bme/data/lds/p10/p10032725/s50331901/687754ce-7420bfd3-0a19911f-a27a3916-9019cd53_clip.pth\n",
      "1.0\n",
      "/public_bme/data/lds/p10/p10439781/s51129150/1d74ca1d-12ac2785-bd84a322-376f04bc-b9fdaa99.jpg /public_bme/data/lds/p10/p10439781/s51129150/1d74ca1d-12ac2785-bd84a322-376f04bc-b9fdaa99_clip.pth\n",
      "2.0\n",
      "/public_bme/data/lds/p10/p10885696/s56443683/5b429228-9769c874-369577de-11d25077-c9ad1f2b.jpg /public_bme/data/lds/p10/p10885696/s56443683/5b429228-9769c874-369577de-11d25077-c9ad1f2b_clip.pth\n",
      "3.0\n",
      "/public_bme/data/lds/p10/p10975446/s55185117/0d768fcf-0bb1bca1-eb1fe1d6-686b876b-675a2e95.jpg /public_bme/data/lds/p10/p10975446/s55185117/0d768fcf-0bb1bca1-eb1fe1d6-686b876b-675a2e95_clip.pth\n",
      "4.0\n",
      "/public_bme/data/lds/p11/p11293517/s51788928/d488ce83-528fa722-abe67b2b-ef58f254-0d7db9b2.jpg /public_bme/data/lds/p11/p11293517/s51788928/d488ce83-528fa722-abe67b2b-ef58f254-0d7db9b2_clip.pth\n",
      "5.0\n",
      "/public_bme/data/lds/p11/p11474065/s59083645/7bcd081b-869f44f4-57a93477-646a8796-ee97546c.jpg /public_bme/data/lds/p11/p11474065/s59083645/7bcd081b-869f44f4-57a93477-646a8796-ee97546c_clip.pth\n",
      "6.0\n",
      "/public_bme/data/lds/p11/p11880923/s56440140/421dff97-6d2b4aab-02ed28a8-54dd67f9-da2f957b.jpg /public_bme/data/lds/p11/p11880923/s56440140/421dff97-6d2b4aab-02ed28a8-54dd67f9-da2f957b_clip.pth\n",
      "7.0\n",
      "/public_bme/data/lds/p12/p12185775/s50729749/42ca390f-5819f578-c74fd59e-a7561a1a-0040b454.jpg /public_bme/data/lds/p12/p12185775/s50729749/42ca390f-5819f578-c74fd59e-a7561a1a-0040b454_clip.pth\n",
      "8.0\n",
      "/public_bme/data/lds/p12/p12475198/s53378145/ba5b5b5f-13d50976-7e931ab9-b5cae769-76a2d17e.jpg /public_bme/data/lds/p12/p12475198/s53378145/ba5b5b5f-13d50976-7e931ab9-b5cae769-76a2d17e_clip.pth\n",
      "9.0\n",
      "/public_bme/data/lds/p12/p12702423/s51244261/17ff7369-20912497-3b539b61-9c4ace20-7dc7fa12.jpg /public_bme/data/lds/p12/p12702423/s51244261/17ff7369-20912497-3b539b61-9c4ace20-7dc7fa12_clip.pth\n",
      "10.0\n",
      "/public_bme/data/lds/p12/p12963531/s59505688/44f44165-06ab81a8-b9d0f4c2-2c65e354-bd5cbfbf.jpg /public_bme/data/lds/p12/p12963531/s59505688/44f44165-06ab81a8-b9d0f4c2-2c65e354-bd5cbfbf_clip.pth\n"
     ]
    }
   ],
   "source": [
    "def fun(x, pre):\n",
    "  x = x.replace(\"//\", '/')\n",
    "  a = x.split(\"/\")\n",
    "  b = a[-4:]\n",
    "  temp = pre + \"/\" + \"/\".join(b)\n",
    "  return(temp)\n",
    "\n",
    "img_paths = data.file_path\n",
    "tensor_path = data.BiomedClip_img_tensor_path\n",
    "total = len(tensor_path)\n",
    "print(total)\n",
    "print(len(tensor_path), len(img_paths))\n",
    "dev = total // 10\n",
    "count = 0\n",
    "# for i, j in enumerate(img_paths):\n",
    "#   print(type(j), j,  tensor_path[i])\n",
    "#   CLIP_Process(str(j), tensor_path[i])\n",
    "#   if i % dev == 0:\n",
    "#     print(i)\n",
    "#   else:\n",
    "#     continue\n",
    "\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "for  (img_path, tensor_path) in (zip(img_paths, tensor_path)):\n",
    "  try:\n",
    "    # print( type(img_path), img_path, type(ten,,l[pl-0o-or_path), tensor_path)\n",
    "    img_path = fun(img_path, source) \n",
    "    BiomedCLIP_processor(img_path, tensor_path)\n",
    "    if count%dev == 0:\n",
    "      print(count/dev)\n",
    "      print(img_path, tensor_path)\n",
    "    count+=1\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_paths = data.file_path\n",
    "tensor_path = data.Clip_img_tensor_path\n",
    "total = len(tensor_path)\n",
    "print(total)\n",
    "print(len(tensor_path), len(img_paths))\n",
    "dev = total // 10\n",
    "count = 0\n",
    "\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "for  (img_path, tensor_path) in (zip(img_paths, tensor_path)):\n",
    "  try:\n",
    "    # print( type(img_path), img_path, type(ten,,l[pl-0o-or_path), tensor_path)\n",
    "    img_path = fun(img_path, source)\n",
    "    CLIP_Process(img_path, tensor_path)\n",
    "    if count%dev == 0:\n",
    "      print(count/dev)\n",
    "      print(img_path, tensor_path)\n",
    "    count+=1\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10//p10046166/s56173345//da33ac9f-b047f007-dd9e0ac7-81b4a35e-bb2b6b5b.jpg\n",
      "1175\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>label</th>\n",
       "      <th>img_path</th>\n",
       "      <th>train_label</th>\n",
       "      <th>file_path</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>10032725</td>\n",
       "      <td>50331901</td>\n",
       "      <td>{'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>10032725</td>\n",
       "      <td>55504914</td>\n",
       "      <td>{'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1825</td>\n",
       "      <td>10046166</td>\n",
       "      <td>50051329</td>\n",
       "      <td>{'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1826</td>\n",
       "      <td>10046166</td>\n",
       "      <td>50051329</td>\n",
       "      <td>{'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1827</td>\n",
       "      <td>10046166</td>\n",
       "      <td>51738740</td>\n",
       "      <td>{'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  subject_id  study_id  \\\n",
       "0        1461    10032725  50331901   \n",
       "1        1462    10032725  55504914   \n",
       "2        1825    10046166  50051329   \n",
       "3        1826    10046166  50051329   \n",
       "4        1827    10046166  51738740   \n",
       "\n",
       "                                               label  \\\n",
       "0  {'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...   \n",
       "1  {'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...   \n",
       "2  {'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...   \n",
       "3  {'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...   \n",
       "4  {'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...   \n",
       "\n",
       "                                            img_path  \\\n",
       "0  D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "1  D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "2  D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "3  D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "4  D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "\n",
       "                               train_label  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]   \n",
       "\n",
       "                                           file_path split  \n",
       "0  D:/project_x_ray_CLIP/data/physionet.org/files...  test  \n",
       "1  D:/project_x_ray_CLIP/data/physionet.org/files...  test  \n",
       "2  D:/project_x_ray_CLIP/data/physionet.org/files...  test  \n",
       "3  D:/project_x_ray_CLIP/data/physionet.org/files...  test  \n",
       "4  D:/project_x_ray_CLIP/data/physionet.org/files...  test  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "pwd = os.getcwd()\n",
    "\n",
    "data = pd.read_csv(pwd + r\"/data/mimic-cxr-train/P10_12_test.csv\")\n",
    "data.head()\n",
    "print(data.file_path[10])\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10//p10032725/s50331901//687754ce-7420bfd3-0a19911f-a27a3916-9019cd53.jpg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>label</th>\n",
       "      <th>img_path</th>\n",
       "      <th>train_label</th>\n",
       "      <th>file_path</th>\n",
       "      <th>split</th>\n",
       "      <th>BiomedClip_img_tensor_path</th>\n",
       "      <th>Clip_img_tensor_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>10032725</td>\n",
       "      <td>50331901</td>\n",
       "      <td>{'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>10032725</td>\n",
       "      <td>55504914</td>\n",
       "      <td>{'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>10046166</td>\n",
       "      <td>50051329</td>\n",
       "      <td>{'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>10046166</td>\n",
       "      <td>50051329</td>\n",
       "      <td>{'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>10046166</td>\n",
       "      <td>51738740</td>\n",
       "      <td>{'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            subject_id  study_id  \\\n",
       "Unnamed: 0                         \n",
       "1461          10032725  50331901   \n",
       "1462          10032725  55504914   \n",
       "1825          10046166  50051329   \n",
       "1826          10046166  50051329   \n",
       "1827          10046166  51738740   \n",
       "\n",
       "                                                        label  \\\n",
       "Unnamed: 0                                                      \n",
       "1461        {'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...   \n",
       "1462        {'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...   \n",
       "1825        {'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...   \n",
       "1826        {'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...   \n",
       "1827        {'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...   \n",
       "\n",
       "                                                     img_path  \\\n",
       "Unnamed: 0                                                      \n",
       "1461        D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "1462        D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "1825        D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "1826        D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "1827        D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "\n",
       "                                        train_label  \\\n",
       "Unnamed: 0                                            \n",
       "1461        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]   \n",
       "1462        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]   \n",
       "1825        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]   \n",
       "1826        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]   \n",
       "1827        [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]   \n",
       "\n",
       "                                                    file_path split  \\\n",
       "Unnamed: 0                                                            \n",
       "1461        D:/project_x_ray_CLIP/data/physionet.org/files...  test   \n",
       "1462        D:/project_x_ray_CLIP/data/physionet.org/files...  test   \n",
       "1825        D:/project_x_ray_CLIP/data/physionet.org/files...  test   \n",
       "1826        D:/project_x_ray_CLIP/data/physionet.org/files...  test   \n",
       "1827        D:/project_x_ray_CLIP/data/physionet.org/files...  test   \n",
       "\n",
       "                                   BiomedClip_img_tensor_path  \\\n",
       "Unnamed: 0                                                      \n",
       "1461        D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "1462        D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "1825        D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "1826        D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "1827        D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "\n",
       "                                         Clip_img_tensor_path  \n",
       "Unnamed: 0                                                     \n",
       "1461        D:/project_x_ray_CLIP/data/physionet.org/files...  \n",
       "1462        D:/project_x_ray_CLIP/data/physionet.org/files...  \n",
       "1825        D:/project_x_ray_CLIP/data/physionet.org/files...  \n",
       "1826        D:/project_x_ray_CLIP/data/physionet.org/files...  \n",
       "1827        D:/project_x_ray_CLIP/data/physionet.org/files...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "file_path = data.file_path\n",
    "filename = file_path[0]\n",
    "print(filename)\n",
    "\n",
    "def change_suffix(filename, custom = \"\"):\n",
    "    # path_obj = Path(filename)\n",
    "    # filename = path_obj.stem\n",
    "    # # print(filename)\n",
    "    # # 构建新的文件路径\n",
    "    # new_file_path = path_obj.with_suffix(new_suffix)\n",
    "    # print(new_file_path)\n",
    "    modified_string = filename.replace(\"//\", \"/\")\n",
    "    filename, file_extension = os.path.splitext(modified_string)\n",
    "    # print(filename)\n",
    "    return filename+f\"_{custom}\"+\".pth\"\n",
    "data['BiomedClip_img_tensor_path'] = data['file_path'].apply(lambda x: change_suffix(x, 'biomed'))\n",
    "data['Clip_img_tensor_path'] = data['file_path'].apply(lambda x: change_suffix(x, \"clip\"))\n",
    "data.to_csv(pwd + r\"/data/mimic-cxr-train/P10_12_test_12_1.csv\", index=False)\n",
    "data = pd.read_csv(pwd + r\"/data/mimic-cxr-train/P10_12_test_12_1.csv\", index_col=0)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customize data path in ws (generalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(pwd + r\"/data/mimic-cxr-train/P10_12_test_12_1.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10/p10032725/s50331901/687754ce-7420bfd3-0a19911f-a27a3916-9019cd53_clip.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>img_path</th>\n",
       "      <th>train_label</th>\n",
       "      <th>file_path</th>\n",
       "      <th>split</th>\n",
       "      <th>BiomedClip_img_tensor_path</th>\n",
       "      <th>Clip_img_tensor_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50331901</th>\n",
       "      <td>{'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "      <td>/public_bme/data/lds/p10/p10032725/s50331901/6...</td>\n",
       "      <td>/public_bme/data/lds/p10/p10032725/s50331901/6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55504914</th>\n",
       "      <td>{'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "      <td>/public_bme/data/lds/p10/p10032725/s55504914/f...</td>\n",
       "      <td>/public_bme/data/lds/p10/p10032725/s55504914/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50051329</th>\n",
       "      <td>{'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "      <td>/public_bme/data/lds/p10/p10046166/s50051329/4...</td>\n",
       "      <td>/public_bme/data/lds/p10/p10046166/s50051329/4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50051329</th>\n",
       "      <td>{'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "      <td>/public_bme/data/lds/p10/p10046166/s50051329/a...</td>\n",
       "      <td>/public_bme/data/lds/p10/p10046166/s50051329/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51738740</th>\n",
       "      <td>{'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "      <td>/public_bme/data/lds/p10/p10046166/s51738740/3...</td>\n",
       "      <td>/public_bme/data/lds/p10/p10046166/s51738740/3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59505688</th>\n",
       "      <td>{'Atelectasis': 2, 'Cardiomegaly': 0, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "      <td>/public_bme/data/lds/p12/p12963531/s59505688/4...</td>\n",
       "      <td>/public_bme/data/lds/p12/p12963531/s59505688/4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59505688</th>\n",
       "      <td>{'Atelectasis': 2, 'Cardiomegaly': 0, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "      <td>/public_bme/data/lds/p12/p12963531/s59505688/5...</td>\n",
       "      <td>/public_bme/data/lds/p12/p12963531/s59505688/5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55553875</th>\n",
       "      <td>{'Atelectasis': 2, 'Cardiomegaly': 2, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "      <td>/public_bme/data/lds/p12/p12966004/s55553875/d...</td>\n",
       "      <td>/public_bme/data/lds/p12/p12966004/s55553875/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57399078</th>\n",
       "      <td>{'Atelectasis': 2, 'Cardiomegaly': 2, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "      <td>/public_bme/data/lds/p12/p12966004/s57399078/8...</td>\n",
       "      <td>/public_bme/data/lds/p12/p12966004/s57399078/8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59842808</th>\n",
       "      <td>{'Atelectasis': 2, 'Cardiomegaly': 2, 'Consoli...</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2]</td>\n",
       "      <td>D:/project_x_ray_CLIP/data/physionet.org/files...</td>\n",
       "      <td>test</td>\n",
       "      <td>/public_bme/data/lds/p12/p12966004/s59842808/b...</td>\n",
       "      <td>/public_bme/data/lds/p12/p12966004/s59842808/b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1175 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      label  \\\n",
       "study_id                                                      \n",
       "50331901  {'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...   \n",
       "55504914  {'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...   \n",
       "50051329  {'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...   \n",
       "50051329  {'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...   \n",
       "51738740  {'Atelectasis': 1, 'Cardiomegaly': 1, 'Consoli...   \n",
       "...                                                     ...   \n",
       "59505688  {'Atelectasis': 2, 'Cardiomegaly': 0, 'Consoli...   \n",
       "59505688  {'Atelectasis': 2, 'Cardiomegaly': 0, 'Consoli...   \n",
       "55553875  {'Atelectasis': 2, 'Cardiomegaly': 2, 'Consoli...   \n",
       "57399078  {'Atelectasis': 2, 'Cardiomegaly': 2, 'Consoli...   \n",
       "59842808  {'Atelectasis': 2, 'Cardiomegaly': 2, 'Consoli...   \n",
       "\n",
       "                                                   img_path  \\\n",
       "study_id                                                      \n",
       "50331901  D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "55504914  D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "50051329  D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "50051329  D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "51738740  D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "...                                                     ...   \n",
       "59505688  D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "59505688  D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "55553875  D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "57399078  D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "59842808  D:/project_x_ray_CLIP/data/physionet.org/files...   \n",
       "\n",
       "                                      train_label  \\\n",
       "study_id                                            \n",
       "50331901  [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]   \n",
       "55504914  [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]   \n",
       "50051329  [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]   \n",
       "50051329  [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]   \n",
       "51738740  [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]   \n",
       "...                                           ...   \n",
       "59505688  [2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2]   \n",
       "59505688  [2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2]   \n",
       "55553875  [2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2]   \n",
       "57399078  [2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1]   \n",
       "59842808  [2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2]   \n",
       "\n",
       "                                                  file_path split  \\\n",
       "study_id                                                            \n",
       "50331901  D:/project_x_ray_CLIP/data/physionet.org/files...  test   \n",
       "55504914  D:/project_x_ray_CLIP/data/physionet.org/files...  test   \n",
       "50051329  D:/project_x_ray_CLIP/data/physionet.org/files...  test   \n",
       "50051329  D:/project_x_ray_CLIP/data/physionet.org/files...  test   \n",
       "51738740  D:/project_x_ray_CLIP/data/physionet.org/files...  test   \n",
       "...                                                     ...   ...   \n",
       "59505688  D:/project_x_ray_CLIP/data/physionet.org/files...  test   \n",
       "59505688  D:/project_x_ray_CLIP/data/physionet.org/files...  test   \n",
       "55553875  D:/project_x_ray_CLIP/data/physionet.org/files...  test   \n",
       "57399078  D:/project_x_ray_CLIP/data/physionet.org/files...  test   \n",
       "59842808  D:/project_x_ray_CLIP/data/physionet.org/files...  test   \n",
       "\n",
       "                                 BiomedClip_img_tensor_path  \\\n",
       "study_id                                                      \n",
       "50331901  /public_bme/data/lds/p10/p10032725/s50331901/6...   \n",
       "55504914  /public_bme/data/lds/p10/p10032725/s55504914/f...   \n",
       "50051329  /public_bme/data/lds/p10/p10046166/s50051329/4...   \n",
       "50051329  /public_bme/data/lds/p10/p10046166/s50051329/a...   \n",
       "51738740  /public_bme/data/lds/p10/p10046166/s51738740/3...   \n",
       "...                                                     ...   \n",
       "59505688  /public_bme/data/lds/p12/p12963531/s59505688/4...   \n",
       "59505688  /public_bme/data/lds/p12/p12963531/s59505688/5...   \n",
       "55553875  /public_bme/data/lds/p12/p12966004/s55553875/d...   \n",
       "57399078  /public_bme/data/lds/p12/p12966004/s57399078/8...   \n",
       "59842808  /public_bme/data/lds/p12/p12966004/s59842808/b...   \n",
       "\n",
       "                                       Clip_img_tensor_path  \n",
       "study_id                                                     \n",
       "50331901  /public_bme/data/lds/p10/p10032725/s50331901/6...  \n",
       "55504914  /public_bme/data/lds/p10/p10032725/s55504914/f...  \n",
       "50051329  /public_bme/data/lds/p10/p10046166/s50051329/4...  \n",
       "50051329  /public_bme/data/lds/p10/p10046166/s50051329/a...  \n",
       "51738740  /public_bme/data/lds/p10/p10046166/s51738740/3...  \n",
       "...                                                     ...  \n",
       "59505688  /public_bme/data/lds/p12/p12963531/s59505688/4...  \n",
       "59505688  /public_bme/data/lds/p12/p12963531/s59505688/5...  \n",
       "55553875  /public_bme/data/lds/p12/p12966004/s55553875/d...  \n",
       "57399078  /public_bme/data/lds/p12/p12966004/s57399078/8...  \n",
       "59842808  /public_bme/data/lds/p12/p12966004/s59842808/b...  \n",
       "\n",
       "[1175 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(pwd + r\"/data/mimic-cxr-train/P10_12_train_12_1.csv\", index_col=0)\n",
    "data.head()\n",
    "print(data.Clip_img_tensor_path.iloc[0])\n",
    "def fun(x, pre):\n",
    "  a = x.split(\"/\")\n",
    "  b = a[-4:]\n",
    "  temp = pre + \"/\" + \"/\".join(b)\n",
    "  return(temp)\n",
    "def generalize_path(df, loc=None, pre = None):\n",
    "  df[\"BiomedClip_img_tensor_path\"] = df[\"BiomedClip_img_tensor_path\"].apply(lambda x: fun(x, pre))\n",
    "  df[\"Clip_img_tensor_path\"] = df[\"Clip_img_tensor_path\"].apply(lambda x: fun(x, pre))\n",
    "  df.to_csv(loc, index=False)\n",
    "  \n",
    "  # print(df)\n",
    "\n",
    "  return df\n",
    "\n",
    "generalize_path(data, pre = \"/public_bme/data/lds\", loc = pwd + r\"/data/mimic-cxr-train/P10_12_train_12_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1175"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'tensor_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11404\\2614486809.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimg_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtensor_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda\\envs\\biomedCLIP\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6200\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6201\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6202\u001b[0m         ):\n\u001b[0;32m   6203\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6204\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'tensor_path'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "img_paths = data.file_path\n",
    "tensor_path = data.tensor_path\n",
    "total = len(tensor_path)\n",
    "print(len(tensor_path), len(img_paths))\n",
    "dev = total // 10\n",
    "count = 0\n",
    "# for i, j in enumerate(img_paths):\n",
    "#   print(type(j), j,  tensor_path[i])\n",
    "#   CLIP_Process(str(j), tensor_path[i])\n",
    "#   if i % dev == 0:\n",
    "#     print(i)\n",
    "#   else:\n",
    "#     continue\n",
    "\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "for  (img_path, tensor_path) in (zip(img_paths, tensor_path)):\n",
    "  try:\n",
    "    # print( type(img_path), img_path, type(ten,,l[pl-0o-or_path), tensor_path)\n",
    "    CLIP_Process(img_path, tensor_path)\n",
    "    if count%dev == 0:\n",
    "      print(count/dev)\n",
    "      print(img_path, tensor_path)\n",
    "    count+=1\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "    \n",
    "    \n",
    "img_paths = data.file_path\n",
    "tensor_path = data.BiomedClip_tensor_path\n",
    "total = len(tensor_path)\n",
    "print(total)\n",
    "print(len(tensor_path), len(img_paths))\n",
    "dev = total // 10\n",
    "count = 0\n",
    "# for i, j in enumerate(img_paths):\n",
    "#   print(type(j), j,  tensor_path[i])\n",
    "#   CLIP_Process(str(j), tensor_path[i])\n",
    "#   if i % dev == 0:\n",
    "#     print(i)\n",
    "#   else:\n",
    "#     continue\n",
    "\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "for  (img_path, tensor_path) in (zip(img_paths, tensor_path)):\n",
    "  try:\n",
    "    # print( type(img_path), img_path, type(ten,,l[pl-0o-or_path), tensor_path)\n",
    "    BiomedCLIP_processor(img_path, tensor_path)\n",
    "    if count%dev == 0:\n",
    "      print(count/dev)\n",
    "      print(img_path, tensor_path)\n",
    "    count+=1\n",
    "  except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10/p10032725/s50331901/687754ce-7420bfd3-0a19911f-a27a3916-9019cd53.pth'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data[\"tensor_path\"][1461])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red size=5>convert textual prompts into tensors</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/urllib3/connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     sock \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    204\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport),\n\u001b[1;32m    205\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[1;32m    206\u001b[0m         source_address\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address,\n\u001b[1;32m    207\u001b[0m         socket_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_options,\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[1;32m     74\u001b[0m \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 101] Network is unreachable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/urllib3/connectionpool.py:491\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    490\u001b[0m         new_e \u001b[39m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[39m.\u001b[39mproxy\u001b[39m.\u001b[39mscheme)\n\u001b[0;32m--> 491\u001b[0m     \u001b[39mraise\u001b[39;00m new_e\n\u001b[1;32m    493\u001b[0m \u001b[39m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    468\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/urllib3/connectionpool.py:1096\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[39mif\u001b[39;00m conn\u001b[39m.\u001b[39mis_closed:\n\u001b[0;32m-> 1096\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1098\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/urllib3/connection.py:611\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    610\u001b[0m sock: socket\u001b[39m.\u001b[39msocket \u001b[39m|\u001b[39m ssl\u001b[39m.\u001b[39mSSLSocket\n\u001b[0;32m--> 611\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    612\u001b[0m server_hostname: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/urllib3/connection.py:218\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 218\u001b[0m     \u001b[39mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    219\u001b[0m         \u001b[39mself\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to establish a new connection: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    220\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7f16a4ed11c0>: Failed to establish a new connection: [Errno 101] Network is unreachable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/urllib3/connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    842\u001b[0m     new_e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, new_e)\n\u001b[0;32m--> 844\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    845\u001b[0m     method, url, error\u001b[39m=\u001b[39;49mnew_e, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    846\u001b[0m )\n\u001b[1;32m    847\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/urllib3/util/retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    514\u001b[0m     reason \u001b[39m=\u001b[39m error \u001b[39mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 515\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[39mfrom\u001b[39;00m \u001b[39mreason\u001b[39;00m  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract/resolve/main/config.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f16a4ed11c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/huggingface_hub/file_download.py:1247\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1247\u001b[0m     metadata \u001b[39m=\u001b[39m get_hf_file_metadata(\n\u001b[1;32m   1248\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m   1249\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1250\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1251\u001b[0m         timeout\u001b[39m=\u001b[39;49metag_timeout,\n\u001b[1;32m   1252\u001b[0m     )\n\u001b[1;32m   1253\u001b[0m \u001b[39mexcept\u001b[39;00m EntryNotFoundError \u001b[39mas\u001b[39;00m http_error:\n\u001b[1;32m   1254\u001b[0m     \u001b[39m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/huggingface_hub/file_download.py:1624\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[1;32m   1623\u001b[0m \u001b[39m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1624\u001b[0m r \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1625\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mHEAD\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1626\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m   1627\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m   1628\u001b[0m     allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1629\u001b[0m     follow_relative_redirects\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1630\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1631\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m   1632\u001b[0m )\n\u001b[1;32m   1633\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/huggingface_hub/file_download.py:402\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 402\u001b[0m     response \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[1;32m    403\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    404\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    405\u001b[0m         follow_relative_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    406\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams,\n\u001b[1;32m    407\u001b[0m     )\n\u001b[1;32m    409\u001b[0m     \u001b[39m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     \u001b[39m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/huggingface_hub/file_download.py:425\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[39m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m response \u001b[39m=\u001b[39m get_session()\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    426\u001b[0m hf_raise_for_status(response)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/huggingface_hub/utils/_http.py:63\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     64\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/requests/adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m--> 519\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    521\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectionError\u001b[0m: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract/resolve/main/config.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f16a4ed11c0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: 096f98c9-6c99-471c-9781-15cbbe6c7dd0)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mLocalEntryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/transformers/utils/hub.py:430\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    431\u001b[0m         path_or_repo_id,\n\u001b[1;32m    432\u001b[0m         filename,\n\u001b[1;32m    433\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    434\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    435\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    436\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    437\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    438\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    439\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    440\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    441\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    442\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    443\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[39mexcept\u001b[39;00m GatedRepoError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/huggingface_hub/file_download.py:1377\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1375\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n\u001b[0;32m-> 1377\u001b[0m         \u001b[39mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[1;32m   1378\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAn error happened while trying to locate the file on the Hub and we cannot find the requested files\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1379\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m in the local cache. Please check your connection and try again or make sure your Internet connection\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1380\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m is on.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1381\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39mhead_call_error\u001b[39;00m\n\u001b[1;32m   1383\u001b[0m \u001b[39m# From now on, etag and commit_hash are not None.\u001b[39;00m\n",
      "\u001b[0;31mLocalEntryNotFoundError\u001b[0m: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m         pth_path \u001b[39m=\u001b[39m path \u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackbone \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprompt \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m         torch\u001b[39m.\u001b[39msave(text_features, pth_path)\n\u001b[0;32m---> 75\u001b[0m test \u001b[39m=\u001b[39m Prompt_preprocess(nntype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbiomedclip\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     76\u001b[0m test\u001b[39m.\u001b[39mprocess(save\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m, in \u001b[0;36mPrompt_preprocess.__init__\u001b[0;34m(self, text_embedding_dim, num_transformer_heads, num_transformer_layers, proj_bias, nntype, prompt_type)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mopen_clip\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclip_model, _, _ \u001b[39m=\u001b[39m open_clip\u001b[39m.\u001b[39mcreate_model_and_transforms(\u001b[39m'\u001b[39m\u001b[39mhf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39m=\u001b[39m open_clip\u001b[39m.\u001b[39;49mget_tokenizer(\u001b[39m'\u001b[39;49m\u001b[39mhf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     34\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackbone \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcustom\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     35\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplemented\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mhas not implemented the custom backbone in text branch\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/open_clip/factory.py:114\u001b[0m, in \u001b[0;36mget_tokenizer\u001b[0;34m(model_name, context_length, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m     context_length \u001b[39m=\u001b[39m text_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mcontext_length\u001b[39m\u001b[39m'\u001b[39m, DEFAULT_CONTEXT_LENGTH)\n\u001b[1;32m    113\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mhf_tokenizer_name\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m text_config:\n\u001b[0;32m--> 114\u001b[0m     tokenizer \u001b[39m=\u001b[39m HFTokenizer(\n\u001b[1;32m    115\u001b[0m         text_config[\u001b[39m'\u001b[39;49m\u001b[39mhf_tokenizer_name\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    116\u001b[0m         context_length\u001b[39m=\u001b[39;49mcontext_length,\n\u001b[1;32m    117\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtokenizer_kwargs,\n\u001b[1;32m    118\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     tokenizer \u001b[39m=\u001b[39m SimpleTokenizer(\n\u001b[1;32m    121\u001b[0m         context_length\u001b[39m=\u001b[39mcontext_length,\n\u001b[1;32m    122\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtokenizer_kwargs,\n\u001b[1;32m    123\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/open_clip/tokenizer.py:407\u001b[0m, in \u001b[0;36mHFTokenizer.__init__\u001b[0;34m(self, tokenizer_name, context_length, clean, strip_sep_token)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    400\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    401\u001b[0m         tokenizer_name: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    404\u001b[0m         strip_sep_token: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    405\u001b[0m ):\n\u001b[1;32m    406\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer\n\u001b[0;32m--> 407\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(tokenizer_name)\n\u001b[1;32m    408\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext_length \u001b[39m=\u001b[39m context_length\n\u001b[1;32m    409\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclean_fn \u001b[39m=\u001b[39m get_clean_fn(clean)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py:733\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[39mif\u001b[39;00m config_tokenizer_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m--> 733\u001b[0m         config \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    734\u001b[0m             pretrained_model_name_or_path, trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    735\u001b[0m         )\n\u001b[1;32m    736\u001b[0m     config_tokenizer_class \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mtokenizer_class\n\u001b[1;32m    737\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(config, \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoTokenizer\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mauto_map:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py:1048\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1045\u001b[0m trust_remote_code \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mtrust_remote_code\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1046\u001b[0m code_revision \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mcode_revision\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 1048\u001b[0m config_dict, unused_kwargs \u001b[39m=\u001b[39m PretrainedConfig\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1049\u001b[0m has_remote_code \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoConfig\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1050\u001b[0m has_local_code \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/transformers/configuration_utils.py:622\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    621\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    623\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n\u001b[1;32m    624\u001b[0m     original_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m config_dict[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/transformers/configuration_utils.py:677\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m configuration_file \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39m_configuration_file\u001b[39m\u001b[39m\"\u001b[39m, CONFIG_NAME)\n\u001b[1;32m    675\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    676\u001b[0m     \u001b[39m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m    678\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    679\u001b[0m         configuration_file,\n\u001b[1;32m    680\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    681\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    682\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    683\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    684\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    685\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    686\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    687\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    688\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    689\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m    690\u001b[0m     )\n\u001b[1;32m    691\u001b[0m     commit_hash \u001b[39m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    692\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    693\u001b[0m     \u001b[39m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    694\u001b[0m     \u001b[39m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/transformers/utils/hub.py:470\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _raise_exceptions_for_missing_entries \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m _raise_exceptions_for_connection_errors:\n\u001b[1;32m    469\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 470\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    471\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWe couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt connect to \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to load this file, couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find it in the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    472\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m cached files and it looks like \u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m is not the path to a directory containing a file named\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    473\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mfull_filename\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCheckout your internet connection or see how to run the library in offline mode at\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    474\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    475\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[39mexcept\u001b[39;00m EntryNotFoundError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    477\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _raise_exceptions_for_missing_entries:\n",
      "\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # 将上级目录添加到sys.path中\n",
    "from constants import BASIC_PROMPT\n",
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from typing import Any, Dict, Optional, Tuple, Union\n",
    "import open_clip\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torchvision.transforms import InterpolationMode\n",
    "# print(f'\\033[31mthe type of text_inputs : {type(text_inputs)}\\033[0m')\n",
    "\n",
    "\n",
    "class Prompt_preprocess(nn.Module):\n",
    "    def __init__(self, text_embedding_dim = 512, num_transformer_heads = 8, num_transformer_layers = 6, proj_bias = False, nntype = None, prompt_type = \"basic\"):\n",
    "        super().__init__()\n",
    "        # 初始化 CLIP 预训练模型和处理器\n",
    "        self.projection_head = nn.Linear(512, 512, bias=False)\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.prompt = prompt_type\n",
    "        if nntype == None:\n",
    "            self.backbone = \"clip\"\n",
    "        else:\n",
    "          self.backbone = nntype        \n",
    "        if self.backbone in [\"biomed\", \"BiomedCLIP\", \"biomedclip\"]:\n",
    "            import open_clip\n",
    "            self.clip_model, _, _ = open_clip.create_model_and_transforms('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
    "            self.tokenizer = open_clip.get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
    "        elif self.backbone == \"custom\":\n",
    "            raise NotImplemented(\"has not implemented the custom backbone in text branch\")\n",
    "        else:\n",
    "            ## the default backbone is CLIP -- text encoder\n",
    "            self.clip_model, self.clip_processor  = clip.load(\"ViT-B/32\", device=self.device)\n",
    "        # 冻结 CLIP 部分的参数\n",
    "        if self.backbone != \"custom\":\n",
    "          for param in self.clip_model.parameters():\n",
    "              param.requires_grad = False\n",
    "        # text orthogonal 部分\n",
    "    \n",
    "    def process(self, save = False, path = r\"/home_data/home/v-liudsh/coding/constrastive_P/diagnosisP/exchange/Fine-Grained_Features_Alignment_via_Constrastive_Learning/data/prompts_tensors/basic\"):\n",
    "      text_features = []\n",
    "      with torch.no_grad():\n",
    "          for text_input in BASIC_PROMPT:\n",
    "            print(\">>>>>>>>>>>>>>>>>>>\",text_input)\n",
    "            if self.backbone in [\"biomed\", \"BiomedCLIP\", \"biomedclip\"]:\n",
    "                context_length = 256\n",
    "                self.clip_model.to(self.device)\n",
    "                self.clip_model.eval()\n",
    "                # print(self.tokenizer(text_input, context_length=context_length).cuda())\n",
    "                _, text_feature, _= self.clip_model(None, self.tokenizer(text_input, context_length=context_length).cuda())\n",
    "                # text_feature = torch.tensor(text_feature)\n",
    "                text_feature = text_feature.clone().detach()\n",
    "                text_feature /= text_feature.norm(dim=-1, keepdim=True)\n",
    "                text_features.append(text_feature)                  \n",
    "            else:\n",
    "                text_feature = self.clip_model.encode_text(clip.tokenize(text_input)).float()\n",
    "                text_feature /= text_feature.norm(dim=-1, keepdim=True)\n",
    "                text_features.append(text_feature)\n",
    "      # text-features shape - [batch, num of text, dim]\n",
    "      # print(len(text_features), torch.tensor(text_features[0]).shape)\n",
    "      text_features = torch.stack(text_features, dim = 0).squeeze()\n",
    "      if save:\n",
    "        folder = os.path.exists(path)\n",
    "         \n",
    "        if not folder:                   #判断是否存在文件夹如果不存在则创建为文件夹\n",
    "          os.makedirs(path)            #makedirs 创建文件时如果路径不存在会创建这个路径\n",
    "        pth_path = path +\"/\" + self.backbone + \"_\" + self.prompt + \".pt\"\n",
    "        torch.save(text_features, pth_path)\n",
    "          \n",
    "test = Prompt_preprocess(nntype=\"biomedclip\")\n",
    "test.process(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 512])\n",
      "torch.Size([13, 512])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.load(r\"D:\\exchange\\ShanghaiTech\\learning\\code\\diagnosisP\\x_ray_constrastive\\data\\prompts_tensors\\basic\\clip_basic.pt\")\n",
    "print(tensor.shape)\n",
    "tensor1 = torch.load(r\"D:\\exchange\\ShanghaiTech\\learning\\code\\diagnosisP\\x_ray_constrastive\\data\\prompts_tensors\\basic\\biomedclip_basic.pt\")\n",
    "print(tensor1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# csv 数据转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(r\"D:\\exchange\\ShanghaiTech\\learning\\code\\diagnosisP\\x_ray_constrastive\\data\\mimic-cxr-train\\P10_12_train_11_19.csv\", index_col=0)\n",
    "print(train.head().iloc[0].tensor_path)    \n",
    "\n",
    "def replace(x):\n",
    "  tensor_path = x.replace(\"D:/project_x_ray_CLIP/data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/\", \"/public_bme/data/lds/\")\n",
    "  temp = tensor_path.split(\".\")\n",
    "  clip = temp[0]+ \"_clip\"\n",
    "  biomed = temp[0] + \"_biomed\"\n",
    "  clip = \".\".join(clip)\n",
    "  biomed = \".\".join(biomed)\n",
    "  return clip, biomed\n",
    "\n",
    "train[\"ws_tensor_path\"] , train[\"ws_biomed_tensor_path\"]= train.tensor_path.apply(lambda x: replace(x))\n",
    "\n",
    "train\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomedCLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
