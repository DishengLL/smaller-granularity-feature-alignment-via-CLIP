{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each label column contains one of four values: 1.0, -1.0, 0.0, or missing. These labels have the following interpretation:\n",
    "\n",
    "- 1.0 - The label was positively mentioned in the associated study, and is present in one or more of the corresponding images\n",
    "e.g. \"A large pleural effusion\"   \n",
    "- 0.0 - The label was negatively mentioned in the associated study, and therefore should not be present in any of the corresponding images\n",
    "e.g. \"No pneumothorax.\"   \n",
    "- -1.0 - The label was either: \n",
    "  (1) mentioned with uncertainty in the report, and therefore may or may not be present to some degree in the corresponding image, or (2) mentioned with ambiguous language in the report and it is unclear if the pathology exists or not    \n",
    "  Explicit uncertainty: \"The cardiac size cannot be evaluated.\"  \n",
    "  Ambiguous language: \"The cardiac contours are stable.\"  \n",
    "- Missing (empty element) - No mention of the label was made in the report\n",
    "---\n",
    "In this project, I using   \n",
    "`1` represent `positive`; (same with the original category indicator)   \n",
    "`0` represent `negative`; (same with the original category indicator)  \n",
    "`0` represent `Nan`; Reasonably assume that `Missing` value in the original table indicates the absence of certain of disease, in this case, `Nan` is replace by `0`;  \n",
    "`uncertainty` is more complicate to preprocess, and there are multiple strategies:  \n",
    "- binary: categorize the `uncertainty` into no-postive case, in this it would be represented with 0\n",
    "- binary_2: reference the strategies used in the paper [[1]](https://arxiv.org/pdf/1901.07031.pdf) and [[2]](https://arxiv.org/pdf/2211.14929)\n",
    "  - `Atelectasis` and `Edema`: U-ones\n",
    "  - `Cardiomegaly`: multi-class\n",
    "  - *`rest`*: U-zeros\n",
    "  - `ignore`: U-ignore, ignore the uncertainty cases and training with mask binary cross entropy\n",
    "  - > Strategy_1 : `Atelectasis`, `Edema`: U-ones; and the `rest`: U-zeros.\n",
    "  - > Strategy_2 : U-ignore, ignore the uncertainty cases\n",
    "  \n",
    "- multiple-classes: in this case, `uncertainty` will be viewed as a independent indicator, and would be represented with -1 \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import clip\n",
    "import torch\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from typing import Any, Dict, Optional, Tuple, Union\n",
    "import open_clip\n",
    "import copy\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import os\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load original dateset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data = pd.read_csv(\"/home_data/home/v-liudsh/coding/constrastive_P/diagnosisP/exchange/Fine-Grained_Features_Alignment_via_Constrastive_Learning/data/project_using_data/mimic-cxr-2.0.0-split.csv\")\n",
    "original_label_data = pd.read_csv(\"/home_data/home/v-liudsh/coding/constrastive_P/diagnosisP/exchange/Fine-Grained_Features_Alignment_via_Constrastive_Learning/data/project_using_data/mimic-cxr-2.0.0-chexpert.csv\")\n",
    "original_meta_data = pd.read_csv(\"/home_data/home/v-liudsh/coding/constrastive_P/diagnosisP/exchange/Fine-Grained_Features_Alignment_via_Constrastive_Learning/data/project_using_data/mimic-cxr-2.0.0-metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dicom_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>split</th>\n",
       "      <th>original_14_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58215</th>\n",
       "      <td>1a671a62-0a32dfc6-5f85029c-81c3922e-3f5a2c27</td>\n",
       "      <td>58235663</td>\n",
       "      <td>11573679</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           dicom_id  study_id  subject_id  \\\n",
       "58215  1a671a62-0a32dfc6-5f85029c-81c3922e-3f5a2c27  58235663    11573679   \n",
       "\n",
       "       split original_14_labels  \n",
       "58215  train               None  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "original_label_data[original_label_data['study_id']==58235663]\n",
    "\n",
    "split_data[split_data['study_id']==58235663]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### extract 14 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_14_label_4_each_record(original_df = None):\n",
    "  # for index, row in original_df.iterrows():\n",
    "    label_dic = {}\n",
    "    for column_name, column_data in original_df.items():\n",
    "      if column_name in [\"subject_id\", 'study_id', \"original_14_labels\", \"strategy1_14_labels\"]:\n",
    "        continue\n",
    "      label_dic[column_name] = 0 if pd.isnull(column_data) else column_data\n",
    "    return label_dic\n",
    "  \n",
    "original_label_data[\"original_14_labels\"] = original_label_data.apply(extract_14_label_4_each_record, axis=1)\n",
    "\n",
    "def extract_14_label_4_each_record_with_strategy_1(each_row):\n",
    "    label_dic = {}\n",
    "    for column_name, column_data in each_row.items():\n",
    "      if column_name in [\"subject_id\", 'study_id', \"original_14_labels\", \"strategy1_14_labels\"]:\n",
    "        continue\n",
    "      if column_name in ['Atelectasis', 'Edema'] and column_data == -1:\n",
    "        label_dic[column_name] = 1\n",
    "      elif column_name not in ['Atelectasis', 'Edema'] and column_data == -1:\n",
    "        label_dic[column_name] = 0\n",
    "      else:\n",
    "        label_dic[column_name] = 0 if pd.isnull(column_data) else column_data\n",
    "    return label_dic\n",
    "  \n",
    "original_label_data[\"strategy1_14_labels\"] = original_label_data.apply(extract_14_label_4_each_record_with_strategy_1, axis=1)\n",
    "  \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>original_14_labels</th>\n",
       "      <th>strategy1_14_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>50414267</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  study_id                            original_14_labels  \\\n",
       "0    10000032  50414267  (0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)   \n",
       "\n",
       "                            strategy1_14_labels  \n",
       "0  (0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_index = ['subject_id', 'study_id', 'original_14_labels',  'strategy1_14_labels']\n",
    "process_data = original_label_data[col_index]\n",
    "process_data\n",
    "\n",
    "def get_original_14_labels_vector(row):\n",
    "  keys = row['original_14_labels'].keys()\n",
    "  values = row['original_14_labels'].values()\n",
    "  return values\n",
    "\n",
    "def get_strategy1_14_labels_vector(row):\n",
    "  values = row['strategy1_14_labels'].values()\n",
    "  return values\n",
    "  \n",
    "process_data.loc[:,'original_14_labels'] = process_data.apply(get_original_14_labels_vector, axis=1)\n",
    "process_data.loc[:,'strategy1_14_labels'] = process_data.apply(get_strategy1_14_labels_vector, axis=1)\n",
    "process_data.to_csv('/home_data/home/v-liudsh/coding/constrastive_P/diagnosisP/exchange/Fine-Grained_Features_Alignment_via_Constrastive_Learning/data/project_using_data/process_data.csv', index=False)  # index=False 表示不保存行索引\n",
    "process_data.head(1)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### add split data indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split数据集中的数据量要比原始的original data要多，但是两个dataset中的study-id数量是一致的。  \n",
    "同时在split数据集中不存在同一个sid用于不同的目的（train，test，validate）  \n",
    "split数据的增多理解为study-id在该数据表格中的重复更多(一个study，一个label，多个views)    \n",
    "在训练中多个view的图片有一个label。每张图片的label在process data中检索获得\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "构造 `program_data_set` 保存最终项目使用的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dicom_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>split</th>\n",
       "      <th>original_14_labels</th>\n",
       "      <th>strategy1_14_labels</th>\n",
       "      <th>ViewPosition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02aa804e-bde0afdd-112c0b34-7bc16630-4e384014</td>\n",
       "      <td>50414267</td>\n",
       "      <td>10000032</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       dicom_id  study_id  subject_id  split  \\\n",
       "0  02aa804e-bde0afdd-112c0b34-7bc16630-4e384014  50414267    10000032  train   \n",
       "\n",
       "  original_14_labels strategy1_14_labels ViewPosition  \n",
       "0               None                None         None  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program_data_set = split_data.copy()\n",
    "program_data_set.loc[:, \"original_14_labels\"] = None\n",
    "program_data_set.loc[:, \"strategy1_14_labels\"] = None\n",
    "program_data_set.loc[:, \"ViewPosition\"] = None\n",
    "program_data_set.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = process_data.set_index('study_id').to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### add labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add label\n",
    "except_sid_original = []\n",
    "except_sid_original_strategy1 = []\n",
    "\n",
    "def search_label_in_process_and_fill_split_data(row):\n",
    "    study_id = row.study_id\n",
    "\n",
    "    if study_id not in dictionary:\n",
    "      except_sid_original.append(study_id)\n",
    "      return\n",
    "      \n",
    "    original_14_labels = dictionary[study_id][\"original_14_labels\"]\n",
    "    return original_14_labels\n",
    "  \n",
    "def search_Strategy1_label_in_process_and_fill_split_data(row):\n",
    "    study_id = row.study_id\n",
    "    if study_id not in dictionary:\n",
    "      except_sid_original_strategy1.append(study_id)\n",
    "      return\n",
    "    strategy1_14_labels = dictionary[study_id][\"strategy1_14_labels\"]\n",
    "    return strategy1_14_labels\n",
    "  \n",
    "program_data_set[\"original_14_labels\"] = program_data_set.apply(search_label_in_process_and_fill_split_data, axis=1)\n",
    "program_data_set[\"strategy1_14_labels\"] = program_data_set.apply(search_Strategy1_label_in_process_and_fill_split_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = program_data_set['study_id'].isin(except_sid_original)  # 例如，删除满足 A 列大于 3 的行\n",
    "program_data_set = program_data_set[~condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dicom_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>split</th>\n",
       "      <th>original_14_labels</th>\n",
       "      <th>strategy1_14_labels</th>\n",
       "      <th>ViewPosition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02aa804e-bde0afdd-112c0b34-7bc16630-4e384014</td>\n",
       "      <td>50414267</td>\n",
       "      <td>10000032</td>\n",
       "      <td>train</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962</td>\n",
       "      <td>50414267</td>\n",
       "      <td>10000032</td>\n",
       "      <td>train</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a2277a9-b0ded155-c0de8eb9-c124d10e-82c5caab</td>\n",
       "      <td>53189527</td>\n",
       "      <td>10000032</td>\n",
       "      <td>train</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       dicom_id  study_id  subject_id  split  \\\n",
       "0  02aa804e-bde0afdd-112c0b34-7bc16630-4e384014  50414267    10000032  train   \n",
       "1  174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962  50414267    10000032  train   \n",
       "2  2a2277a9-b0ded155-c0de8eb9-c124d10e-82c5caab  53189527    10000032  train   \n",
       "\n",
       "                             original_14_labels  \\\n",
       "0  (0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)   \n",
       "1  (0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)   \n",
       "2  (0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)   \n",
       "\n",
       "                            strategy1_14_labels ViewPosition  \n",
       "0  (0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)         None  \n",
       "1  (0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)         None  \n",
       "2  (0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)         None  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program_data_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_data_set.to_csv(\"/home_data/home/v-liudsh/coding/constrastive_P/diagnosisP/exchange/Fine-Grained_Features_Alignment_via_Constrastive_Learning/data/project_using_data/program_data_set_3_8.csv\", index=False)  # index=False 表示不保存行索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### add view position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add view position\n",
    "meta_dict = original_meta_data.set_index('dicom_id').to_dict(orient = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_view = []\n",
    "for index, row in program_data_set.iterrows():\n",
    "  dicom_id = row.dicom_id\n",
    "  view = meta_dict[dicom_id]['ViewPosition']\n",
    "  all_view.append(view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_data_set.loc[:, \"ViewPosition\"] = all_view\n",
    "program_data_set.to_csv(\"/home_data/home/v-liudsh/coding/constrastive_P/diagnosisP/exchange/Fine-Grained_Features_Alignment_via_Constrastive_Learning/data/project_using_data/program_data_set_3_8.csv\", index=False)  # index=False 表示不保存行索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dicom_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>split</th>\n",
       "      <th>original_14_labels</th>\n",
       "      <th>strategy1_14_labels</th>\n",
       "      <th>ViewPosition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02aa804e-bde0afdd-112c0b34-7bc16630-4e384014</td>\n",
       "      <td>50414267</td>\n",
       "      <td>10000032</td>\n",
       "      <td>train</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962</td>\n",
       "      <td>50414267</td>\n",
       "      <td>10000032</td>\n",
       "      <td>train</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>LATERAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a2277a9-b0ded155-c0de8eb9-c124d10e-82c5caab</td>\n",
       "      <td>53189527</td>\n",
       "      <td>10000032</td>\n",
       "      <td>train</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e084de3b-be89b11e-20fe3f9f-9c8d8dfe-4cfd202c</td>\n",
       "      <td>53189527</td>\n",
       "      <td>10000032</td>\n",
       "      <td>train</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>LATERAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68b5c4b1-227d0485-9cc38c3f-7b84ab51-4b472714</td>\n",
       "      <td>53911762</td>\n",
       "      <td>10000032</td>\n",
       "      <td>train</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>(0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)</td>\n",
       "      <td>AP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       dicom_id  study_id  subject_id  split  \\\n",
       "0  02aa804e-bde0afdd-112c0b34-7bc16630-4e384014  50414267    10000032  train   \n",
       "1  174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962  50414267    10000032  train   \n",
       "2  2a2277a9-b0ded155-c0de8eb9-c124d10e-82c5caab  53189527    10000032  train   \n",
       "3  e084de3b-be89b11e-20fe3f9f-9c8d8dfe-4cfd202c  53189527    10000032  train   \n",
       "4  68b5c4b1-227d0485-9cc38c3f-7b84ab51-4b472714  53911762    10000032  train   \n",
       "\n",
       "                             original_14_labels  \\\n",
       "0  (0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)   \n",
       "1  (0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)   \n",
       "2  (0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)   \n",
       "3  (0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)   \n",
       "4  (0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)   \n",
       "\n",
       "                            strategy1_14_labels ViewPosition  \n",
       "0  (0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)           PA  \n",
       "1  (0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)      LATERAL  \n",
       "2  (0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)           PA  \n",
       "3  (0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)      LATERAL  \n",
       "4  (0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0)           AP  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program_data_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### add image_tensor_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic = \"/public_bme/data/lds/\"\n",
    "\n",
    "def get_image_file_path(row):\n",
    "    p = \"p\" + str(row.subject_id)[:2]\n",
    "    pp = 'p' + str(row.subject_id)\n",
    "    s = \"s\" + str(row.study_id)\n",
    "    img = row.dicom_id + \".jpg\"\n",
    "    file_path = f\"{basic}/{p}/{pp}/{s}/{img}\"\n",
    "    return file_path\n",
    "\n",
    "# 获取所有文件路径\n",
    "file_paths = [get_image_file_path(row) for _, row in program_data_set.iterrows()]\n",
    "\n",
    "# 检查所有文件路径是否存在\n",
    "for file_path in file_paths:\n",
    "    assert os.path.exists(file_path)\n",
    "\n",
    "print(\"pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "BiomedClip_img_tensor_paths = [(lambda x: x.replace(\".jpg\", \"_BioMedClip.pth\"))(path) for path in file_paths]\n",
    "Clip_img_tensor_path = [(lambda x: x.replace(\".jpg\", \"_Clip.pth\"))(path) for path in file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_data_set.loc[:,\"image_file_path\"] = file_paths\n",
    "program_data_set.loc[:,\"BiomedClip_img_tensor_path\"] = BiomedClip_img_tensor_paths\n",
    "program_data_set.loc[:,\"Clip_img_tensor_path\"] = Clip_img_tensor_path\n",
    "\n",
    "program_data_set.to_csv(\"/home_data/home/v-liudsh/coding/constrastive_P/diagnosisP/exchange/Fine-Grained_Features_Alignment_via_Constrastive_Learning/data/project_using_data/program_data_set_3_8.csv\", index=False)  # index=False 表示不保存行索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image preprocess logics -- BiomedClip & CLIP\n",
    "try:\n",
    "    BICUBIC = InterpolationMode.BICUBIC\n",
    "except ImportError:\n",
    "    BICUBIC = Image.BICUBIC\n",
    "\n",
    "def _convert_image_to_rgb(image):\n",
    "    return image.convert(\"RGB\")\n",
    "\n",
    "def _transform(n_px):\n",
    "    return Compose([\n",
    "        Resize(n_px, interpolation=BICUBIC),\n",
    "        CenterCrop(n_px),\n",
    "        _convert_image_to_rgb,\n",
    "        ToTensor(),\n",
    "        Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "    ])\n",
    "\n",
    "def CLIP_Process(image_path, dest):\n",
    "    img = Image.open(image_path)\n",
    "    a = 224\n",
    "    b = _transform(a)\n",
    "    c = b(img)\n",
    "    if ((dest.split(\".\")[-1]) != \"pth\"):\n",
    "      dest+=\".pth\"\n",
    "      \n",
    "    torch.save(c, dest)\n",
    "    return c\n",
    "\n",
    "OPENAI_DATASET_MEAN = (0.48145466, 0.4578275, 0.40821073)\n",
    "OPENAI_DATASET_STD = (0.26862954, 0.26130258, 0.27577711)\n",
    "\n",
    "_FIELDS = '__dataclass_fields__'\n",
    "def _is_dataclass_instance(obj):\n",
    "    \"\"\"Returns True if obj is an instance of a dataclass.\"\"\"\n",
    "    return hasattr(type(obj), _FIELDS)\n",
    "\n",
    "def asdict(obj, *, dict_factory=dict):\n",
    "    \"\"\"Return the fields of a dataclass instance as a new dictionary mapping\n",
    "    field names to field values.\n",
    "\n",
    "    Example usage:\n",
    "\n",
    "      @dataclass\n",
    "      class C:\n",
    "          x: int\n",
    "          y: int\n",
    "\n",
    "      c = C(1, 2)\n",
    "      assert asdict(c) == {'x': 1, 'y': 2}\n",
    "\n",
    "    If given, 'dict_factory' will be used instead of built-in dict.\n",
    "    The function applies recursively to field values that are\n",
    "    dataclass instances. This will also look into built-in containers:\n",
    "    tuples, lists, and dicts.\n",
    "    \"\"\"\n",
    "    if not _is_dataclass_instance(obj):\n",
    "        raise TypeError(\"asdict() should be called on dataclass instances\")\n",
    "    return _asdict_inner(obj, dict_factory)\n",
    "\n",
    "def _asdict_inner(obj, dict_factory):\n",
    "    if _is_dataclass_instance(obj):\n",
    "        result = []\n",
    "        for f in fields(obj):\n",
    "            value = _asdict_inner(getattr(obj, f.name), dict_factory)\n",
    "            result.append((f.name, value))\n",
    "        return dict_factory(result)\n",
    "    elif isinstance(obj, tuple) and hasattr(obj, '_fields'):\n",
    "        return type(obj)(*[_asdict_inner(v, dict_factory) for v in obj])\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        # Assume we can create an object of this type by passing in a\n",
    "        # generator (which is not true for namedtuples, handled\n",
    "        # above).\n",
    "        return type(obj)(_asdict_inner(v, dict_factory) for v in obj)\n",
    "    elif isinstance(obj, dict):\n",
    "        return type(obj)((_asdict_inner(k, dict_factory),\n",
    "                          _asdict_inner(v, dict_factory))\n",
    "                         for k, v in obj.items())\n",
    "    else:\n",
    "        return copy.deepcopy(obj)\n",
    "\n",
    "class AugmentationCfg:\n",
    "    scale: Tuple[float, float] = (0.9, 1.0)\n",
    "    ratio: Optional[Tuple[float, float]] = None\n",
    "    color_jitter: Optional[Union[float, Tuple[float, float, float]]] = None\n",
    "    interpolation: Optional[str] = None\n",
    "    re_prob: Optional[float] = None\n",
    "    re_count: Optional[int] = None\n",
    "    use_timm: bool = False\n",
    "\n",
    "class ResizeMaxSize(nn.Module):\n",
    "    def __init__(self, max_size, interpolation=InterpolationMode.BICUBIC, fn='max', fill=0):\n",
    "        super().__init__()\n",
    "        if not isinstance(max_size, int):\n",
    "            raise TypeError(f\"Size should be int. Got {type(max_size)}\")\n",
    "        self.max_size = max_size\n",
    "        self.interpolation = interpolation\n",
    "        self.fn = min if fn == 'min' else min\n",
    "        self.fill = fill\n",
    "\n",
    "    def forward(self, img):\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            height, width = img.shape[:2]\n",
    "        else:\n",
    "            width, height = img.size\n",
    "        scale = self.max_size / float(max(height, width))\n",
    "        new_size = tuple(round(dim * scale) for dim in (height, width))\n",
    "        if scale != 1.0:\n",
    "            img = F.resize(img, new_size, self.interpolation)\n",
    "        if not width == height:\n",
    "            pad_h = self.max_size - new_size[0]\n",
    "            pad_w = self.max_size - new_size[1]\n",
    "            img = F.pad(img, padding=[pad_w//2, pad_h//2, pad_w - pad_w//2, pad_h - pad_h//2], fill=self.fill)\n",
    "        return img\n",
    "\n",
    "def image_transform(\n",
    "        image_size: int,\n",
    "        is_train:bool = False,\n",
    "        mean: Optional[Tuple[float, ...]] = None,\n",
    "        std: Optional[Tuple[float, ...]] = None,\n",
    "        resize_longest_max: bool = False,\n",
    "        fill_color: int = 0,\n",
    "        aug_cfg: Optional[Union[Dict[str, Any], AugmentationCfg]] = None,\n",
    "):\n",
    "    mean = mean or OPENAI_DATASET_MEAN\n",
    "    if not isinstance(mean, (list, tuple)):\n",
    "        mean = (mean,) * 3\n",
    "\n",
    "    std = std or OPENAI_DATASET_STD\n",
    "    if not isinstance(std, (list, tuple)):\n",
    "        std = (std,) * 3\n",
    "\n",
    "    if isinstance(image_size, (list, tuple)) and image_size[0] == image_size[1]:\n",
    "        # for square size, pass size as int so that Resize() uses aspect preserving shortest edge\n",
    "        image_size = image_size[0]\n",
    "\n",
    "    if isinstance(aug_cfg, dict):\n",
    "        aug_cfg = AugmentationCfg(**aug_cfg)\n",
    "    else:\n",
    "        aug_cfg = aug_cfg or AugmentationCfg()\n",
    "    normalize = Normalize(mean=mean, std=std)\n",
    "    if is_train:\n",
    "        raise NotImplemented(\"!!LDS!!\")\n",
    "    else:\n",
    "        if resize_longest_max:\n",
    "            transforms = [\n",
    "                ResizeMaxSize(image_size, fill=fill_color)\n",
    "            ]\n",
    "        else:\n",
    "            transforms = [\n",
    "                Resize(image_size, interpolation=InterpolationMode.BICUBIC),\n",
    "                CenterCrop(image_size),\n",
    "            ]\n",
    "        transforms.extend([\n",
    "            _convert_image_to_rgb,\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "        return Compose(transforms)\n",
    "\n",
    "def BiomedCLIP_processor(image_path, dest):\n",
    "    img = Image.open(image_path)\n",
    "    preprocess_val = image_transform(224)\n",
    "    data = preprocess_val(img)\n",
    "    if ((dest.split(\".\")[-1]) != \"pth\"):\n",
    "      dest+=\".pth\"\n",
    "      \n",
    "    torch.save(data, dest)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate .pth (CLIP and BiomedCLIP)\n",
    "img_paths = data.file_path\n",
    "BiomedClip_tensor_paths = data.BiomedClip_tensor_path\n",
    "total = len(tensor_path)\n",
    "print(total)\n",
    "print(len(tensor_path), len(img_paths))\n",
    "dev = total // 10\n",
    "count = 0\n",
    "\n",
    "for (img_path, tensor_path) in (zip(img_paths, BiomedClip_tensor_paths)):\n",
    "  try:\n",
    "    # print( type(img_path), img_path, type(ten,,l[pl-0o-or_path), tensor_path)\n",
    "    BiomedCLIP_processor(img_path, tensor_path)\n",
    "    if count%dev == 0:\n",
    "      print(count/dev)\n",
    "      print(img_path, tensor_path)\n",
    "    count+=1\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "Clip_img_tensor_paths = data.Clip_img_tensor_path\n",
    "total = len(Clip_img_tensor_paths)\n",
    "print(Clip_img_tensor_paths)\n",
    "print(len(Clip_img_tensor_paths), len(img_paths))\n",
    "dev = total // 10\n",
    "count = 0\n",
    "\n",
    "\n",
    "for  (img_path, tensor_path) in (zip(img_paths, Clip_img_tensor_paths)):\n",
    "  try:\n",
    "    # print( type(img_path), img_path, type(ten,,l[pl-0o-or_path), tensor_path)\n",
    "    CLIP_Process(img_path, tensor_path)\n",
    "    if count%dev == 0:\n",
    "      print(count/dev)\n",
    "      print(img_path, tensor_path)\n",
    "    count+=1\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
